---
filebeat_kafka_ca: /etc/filebeat/certs/kafka_ca.crt
filebeat_add_certs:
  - ca_path: '{{ filebeat_kafka_ca }}'
    ca_content: '{{ lookup("ansible.builtin.file", kafka_ca_cert_path) }}'

filebeat_config:
  filebeat.modules:
    - module: system
      syslog.enabled: true
      syslog.var.use_journald: true
      auth.enabled: true
      auth.var.use_journald: true
    - module: kafka
      log.enabled: true
      log.var.kafka_home: '{{ kafka_path }}'
      log.var.paths:
        - /var/log/kafka/controller.log*
        - /var/log/kafka/server.log*
        - /var/log/kafka/state-change.log*
        - /var/log/kafka/kafka-*.log*
    - module: elasticsearch
      server.enabled: true
      gc.enabled: true
      audit.enabled: true
      slowlog.enabled: true
      deprecation.enabled: true
    - module: kibana
      log.enabled: true
      log.var.paths: [/var/log/kibana/kibana.log*]
      audit.enabled: true
    - module: logstash
      log.enabled: true
      slowlog.enabled: true
  setup.template.settings:
    index.number_of_shards: 2
  output.kafka:
    hosts: '{{ groups["elasticsearch"] |
      map("ansible.builtin.extract", hostvars, "kafka_broker_socket") }}'
    ssl.certificate_authorities: ['{{ filebeat_kafka_ca }}']
    ssl.certificate: '{{ filebeat_cert.cert_path }}'
    ssl.key: '{{ filebeat_cert.key_path }}'
    topic: '%{[event.module]}'
    required_acks: -1
    compression: zstd
    max_message_bytes: 1000000
    version: '2.6.0'
  processors:
    - add_host_metadata:
        when.not.contains.tags: forwarded
    - add_cloud_metadata: ~
    - add_docker_metadata: ~
    - add_kubernetes_metadata: ~
    - decode_json_fields:
        fields: [message]
        max_depth: 3
        target: ""
...
